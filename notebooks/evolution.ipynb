{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import rand, randint\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_vecs_wavelet = pd.read_csv(\"../data/eigen_vecs_wavelet.csv\")\n",
    "eigen_vecs_gray = pd.read_csv(\"../data/eigen_vecs_gray.csv\")\n",
    "wavelet_std_features = pd.read_csv(\"../data/wavelet_std_features.csv\")\n",
    "gray_std_features = pd.read_csv(\"../data/gray_std_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1216</th>\n",
       "      <th>1217</th>\n",
       "      <th>1218</th>\n",
       "      <th>1219</th>\n",
       "      <th>1220</th>\n",
       "      <th>1221</th>\n",
       "      <th>1222</th>\n",
       "      <th>1223</th>\n",
       "      <th>1224</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.552141</td>\n",
       "      <td>0.417563</td>\n",
       "      <td>-0.097526</td>\n",
       "      <td>0.213892</td>\n",
       "      <td>0.513422</td>\n",
       "      <td>0.535479</td>\n",
       "      <td>0.470071</td>\n",
       "      <td>0.599688</td>\n",
       "      <td>0.995303</td>\n",
       "      <td>1.093655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240740</td>\n",
       "      <td>0.088242</td>\n",
       "      <td>-0.210105</td>\n",
       "      <td>-0.312634</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.163147</td>\n",
       "      <td>0.029706</td>\n",
       "      <td>-0.016715</td>\n",
       "      <td>-0.050974</td>\n",
       "      <td>Kim_Jong-Il</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.707605</td>\n",
       "      <td>1.058285</td>\n",
       "      <td>0.798634</td>\n",
       "      <td>1.056439</td>\n",
       "      <td>0.772568</td>\n",
       "      <td>0.882596</td>\n",
       "      <td>1.607739</td>\n",
       "      <td>1.539196</td>\n",
       "      <td>1.368010</td>\n",
       "      <td>1.313639</td>\n",
       "      <td>...</td>\n",
       "      <td>1.434498</td>\n",
       "      <td>1.369982</td>\n",
       "      <td>0.713475</td>\n",
       "      <td>0.692875</td>\n",
       "      <td>0.546367</td>\n",
       "      <td>-0.255205</td>\n",
       "      <td>-1.064934</td>\n",
       "      <td>-1.213023</td>\n",
       "      <td>-1.171687</td>\n",
       "      <td>Kim_Jong-Il</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.694298</td>\n",
       "      <td>0.829691</td>\n",
       "      <td>0.983415</td>\n",
       "      <td>0.931306</td>\n",
       "      <td>0.670054</td>\n",
       "      <td>0.909874</td>\n",
       "      <td>1.397697</td>\n",
       "      <td>1.394208</td>\n",
       "      <td>1.127612</td>\n",
       "      <td>1.249970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021223</td>\n",
       "      <td>0.298454</td>\n",
       "      <td>0.463149</td>\n",
       "      <td>0.302656</td>\n",
       "      <td>-0.201223</td>\n",
       "      <td>-0.874549</td>\n",
       "      <td>-0.554349</td>\n",
       "      <td>-0.402519</td>\n",
       "      <td>-0.482302</td>\n",
       "      <td>Kim_Jong-Il</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033103</td>\n",
       "      <td>0.219485</td>\n",
       "      <td>0.268445</td>\n",
       "      <td>0.293704</td>\n",
       "      <td>0.019686</td>\n",
       "      <td>0.296015</td>\n",
       "      <td>1.463204</td>\n",
       "      <td>1.757874</td>\n",
       "      <td>1.362924</td>\n",
       "      <td>1.321935</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.197654</td>\n",
       "      <td>-1.080682</td>\n",
       "      <td>-1.210680</td>\n",
       "      <td>-1.242481</td>\n",
       "      <td>-1.088001</td>\n",
       "      <td>-0.611160</td>\n",
       "      <td>-0.647857</td>\n",
       "      <td>-1.021585</td>\n",
       "      <td>-1.187903</td>\n",
       "      <td>Kim_Jong-Il</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.417017</td>\n",
       "      <td>0.344503</td>\n",
       "      <td>-0.173195</td>\n",
       "      <td>0.154932</td>\n",
       "      <td>0.393859</td>\n",
       "      <td>0.418852</td>\n",
       "      <td>0.484160</td>\n",
       "      <td>0.376886</td>\n",
       "      <td>0.266048</td>\n",
       "      <td>0.110025</td>\n",
       "      <td>...</td>\n",
       "      <td>1.301302</td>\n",
       "      <td>1.135282</td>\n",
       "      <td>0.729333</td>\n",
       "      <td>0.458901</td>\n",
       "      <td>0.662662</td>\n",
       "      <td>1.065471</td>\n",
       "      <td>0.985344</td>\n",
       "      <td>1.402783</td>\n",
       "      <td>2.424354</td>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>0.091953</td>\n",
       "      <td>0.095439</td>\n",
       "      <td>0.106280</td>\n",
       "      <td>0.096238</td>\n",
       "      <td>0.106066</td>\n",
       "      <td>0.048213</td>\n",
       "      <td>0.062412</td>\n",
       "      <td>0.070286</td>\n",
       "      <td>0.041856</td>\n",
       "      <td>0.150444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072619</td>\n",
       "      <td>-0.235007</td>\n",
       "      <td>-0.550489</td>\n",
       "      <td>-0.497912</td>\n",
       "      <td>-0.990588</td>\n",
       "      <td>-1.339481</td>\n",
       "      <td>-0.896832</td>\n",
       "      <td>-0.597121</td>\n",
       "      <td>-0.570522</td>\n",
       "      <td>Gus_Van_Sant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>-0.723017</td>\n",
       "      <td>-1.374698</td>\n",
       "      <td>-0.926930</td>\n",
       "      <td>-1.261602</td>\n",
       "      <td>-1.267894</td>\n",
       "      <td>0.346733</td>\n",
       "      <td>1.062299</td>\n",
       "      <td>1.097703</td>\n",
       "      <td>1.247735</td>\n",
       "      <td>0.872234</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.222377</td>\n",
       "      <td>-0.158230</td>\n",
       "      <td>0.527500</td>\n",
       "      <td>0.513077</td>\n",
       "      <td>-1.164360</td>\n",
       "      <td>-1.342067</td>\n",
       "      <td>-1.072720</td>\n",
       "      <td>-1.158803</td>\n",
       "      <td>-1.328136</td>\n",
       "      <td>Guy_Hemmings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>1.042449</td>\n",
       "      <td>1.232408</td>\n",
       "      <td>0.718422</td>\n",
       "      <td>1.094761</td>\n",
       "      <td>1.122931</td>\n",
       "      <td>0.980860</td>\n",
       "      <td>1.010454</td>\n",
       "      <td>1.069370</td>\n",
       "      <td>0.999389</td>\n",
       "      <td>0.840748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224155</td>\n",
       "      <td>0.487819</td>\n",
       "      <td>0.698232</td>\n",
       "      <td>0.732792</td>\n",
       "      <td>0.516362</td>\n",
       "      <td>0.046279</td>\n",
       "      <td>-0.223393</td>\n",
       "      <td>-0.111478</td>\n",
       "      <td>0.053074</td>\n",
       "      <td>Guy_Hemmings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>0.467225</td>\n",
       "      <td>0.456406</td>\n",
       "      <td>0.610015</td>\n",
       "      <td>0.503828</td>\n",
       "      <td>0.472147</td>\n",
       "      <td>0.435489</td>\n",
       "      <td>0.368918</td>\n",
       "      <td>0.361424</td>\n",
       "      <td>0.244407</td>\n",
       "      <td>0.269776</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.436577</td>\n",
       "      <td>-2.166024</td>\n",
       "      <td>-1.954376</td>\n",
       "      <td>-1.787004</td>\n",
       "      <td>-1.640348</td>\n",
       "      <td>-1.565958</td>\n",
       "      <td>-1.446946</td>\n",
       "      <td>-1.299056</td>\n",
       "      <td>-1.207270</td>\n",
       "      <td>Guy_Ritchie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>-0.118538</td>\n",
       "      <td>-1.368220</td>\n",
       "      <td>-1.801371</td>\n",
       "      <td>-1.761730</td>\n",
       "      <td>-0.587290</td>\n",
       "      <td>0.054599</td>\n",
       "      <td>0.243862</td>\n",
       "      <td>0.384946</td>\n",
       "      <td>0.489187</td>\n",
       "      <td>0.588413</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120761</td>\n",
       "      <td>1.230793</td>\n",
       "      <td>1.263117</td>\n",
       "      <td>1.203507</td>\n",
       "      <td>1.216816</td>\n",
       "      <td>1.114536</td>\n",
       "      <td>0.940857</td>\n",
       "      <td>0.605037</td>\n",
       "      <td>0.449836</td>\n",
       "      <td>Guy_Ritchie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7101 rows × 1226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.552141  0.417563 -0.097526  0.213892  0.513422  0.535479  0.470071   \n",
       "1     0.707605  1.058285  0.798634  1.056439  0.772568  0.882596  1.607739   \n",
       "2     0.694298  0.829691  0.983415  0.931306  0.670054  0.909874  1.397697   \n",
       "3     0.033103  0.219485  0.268445  0.293704  0.019686  0.296015  1.463204   \n",
       "4     0.417017  0.344503 -0.173195  0.154932  0.393859  0.418852  0.484160   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7096  0.091953  0.095439  0.106280  0.096238  0.106066  0.048213  0.062412   \n",
       "7097 -0.723017 -1.374698 -0.926930 -1.261602 -1.267894  0.346733  1.062299   \n",
       "7098  1.042449  1.232408  0.718422  1.094761  1.122931  0.980860  1.010454   \n",
       "7099  0.467225  0.456406  0.610015  0.503828  0.472147  0.435489  0.368918   \n",
       "7100 -0.118538 -1.368220 -1.801371 -1.761730 -0.587290  0.054599  0.243862   \n",
       "\n",
       "             7         8         9  ...      1216      1217      1218  \\\n",
       "0     0.599688  0.995303  1.093655  ...  0.240740  0.088242 -0.210105   \n",
       "1     1.539196  1.368010  1.313639  ...  1.434498  1.369982  0.713475   \n",
       "2     1.394208  1.127612  1.249970  ... -0.021223  0.298454  0.463149   \n",
       "3     1.757874  1.362924  1.321935  ... -1.197654 -1.080682 -1.210680   \n",
       "4     0.376886  0.266048  0.110025  ...  1.301302  1.135282  0.729333   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7096  0.070286  0.041856  0.150444  ... -0.072619 -0.235007 -0.550489   \n",
       "7097  1.097703  1.247735  0.872234  ... -1.222377 -0.158230  0.527500   \n",
       "7098  1.069370  0.999389  0.840748  ...  0.224155  0.487819  0.698232   \n",
       "7099  0.361424  0.244407  0.269776  ... -2.436577 -2.166024 -1.954376   \n",
       "7100  0.384946  0.489187  0.588413  ...  1.120761  1.230793  1.263117   \n",
       "\n",
       "          1219      1220      1221      1222      1223      1224  \\\n",
       "0    -0.312634  0.003390  0.163147  0.029706 -0.016715 -0.050974   \n",
       "1     0.692875  0.546367 -0.255205 -1.064934 -1.213023 -1.171687   \n",
       "2     0.302656 -0.201223 -0.874549 -0.554349 -0.402519 -0.482302   \n",
       "3    -1.242481 -1.088001 -0.611160 -0.647857 -1.021585 -1.187903   \n",
       "4     0.458901  0.662662  1.065471  0.985344  1.402783  2.424354   \n",
       "...        ...       ...       ...       ...       ...       ...   \n",
       "7096 -0.497912 -0.990588 -1.339481 -0.896832 -0.597121 -0.570522   \n",
       "7097  0.513077 -1.164360 -1.342067 -1.072720 -1.158803 -1.328136   \n",
       "7098  0.732792  0.516362  0.046279 -0.223393 -0.111478  0.053074   \n",
       "7099 -1.787004 -1.640348 -1.565958 -1.446946 -1.299056 -1.207270   \n",
       "7100  1.203507  1.216816  1.114536  0.940857  0.605037  0.449836   \n",
       "\n",
       "              names  \n",
       "0       Kim_Jong-Il  \n",
       "1       Kim_Jong-Il  \n",
       "2       Kim_Jong-Il  \n",
       "3       Kim_Jong-Il  \n",
       "4     Aaron_Peirsol  \n",
       "...             ...  \n",
       "7096   Gus_Van_Sant  \n",
       "7097   Guy_Hemmings  \n",
       "7098   Guy_Hemmings  \n",
       "7099    Guy_Ritchie  \n",
       "7100    Guy_Ritchie  \n",
       "\n",
       "[7101 rows x 1226 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavelet_std_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some parameters for evolutionary algo\n",
    "\n",
    "feature_percentage = 0.25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recognition_Objective:\n",
    "    '''\n",
    "    Class for implementing the recognition objective for selecting best set of individuals in Evolutionary Algo\n",
    "    Trying Vectorized implementation for the code\n",
    "    '''\n",
    "    def __init__(self, eigen_arr = None, data_arr = None, names = None):\n",
    "        self.eigen_arr = eigen_arr\n",
    "        self.data_arr = data_arr\n",
    "        self.df_name = names\n",
    "    \n",
    "    def _eigen_extractor(self, pop, n_pop):\n",
    "        #extracting eigen values based on the population\n",
    "        ## pop must be of size = (n_pop, n_features)\n",
    "        pop_eigens = [] ## eigen vectors for all population\n",
    "        pop1 = pop.astype(bool)\n",
    "        for i in range(n_pop):\n",
    "            pop_eigens.append(self.eigen_arr[:,pop1[i]].T)\n",
    "        return np.asarray(pop_eigens)\n",
    "        \n",
    "    def _sort_score_fn(self, arr):\n",
    "        sim = cosine_similarity(arr)\n",
    "        sorted_indexes = np.argsort(-sim)\n",
    "        recognition_score = 0\n",
    "        for i, indx_arr in enumerate(sorted_indexes):\n",
    "            name = self.df_name[i]\n",
    "            true_indxs = np.where(self.df_name == name)[0]\n",
    "            predicted_index = indx_arr[true_indxs]\n",
    "            recognition_score += (np.sum(predicted_index<=(len(true_indxs)-1))/len(true_indxs))\n",
    "        return recognition_score/(i+1) \n",
    "        \n",
    "    def _recognition(self, pop, n_pop):\n",
    "        pop_eigens = self._eigen_extractor(pop=pop, n_pop=n_pop)\n",
    "        pop_eigens = np.expand_dims(pop_eigens, axis = 1)\n",
    "        result = pop_eigens@np.expand_dims(self.data_arr, axis = 0)\n",
    "        result = result.squeeze()\n",
    "        return list(map(self._sort_score_fn, result))\n",
    "    \n",
    "    \n",
    "class genetic_algorithm:\n",
    "    '''\n",
    "    Class for implementing our Genetic Algorithm\n",
    "    '''\n",
    "    def __init__(self, crossover_rate = 0.9, mutation_rate = 0.001, eigen_arr=None, data_arr=None, names=None):\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.eigen_arr = eigen_arr\n",
    "        self.data_arr = data_arr\n",
    "        self.names = names\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.recognition = Recognition_Objective(eigen_arr=self.eigen_arr, data_arr=self.data_arr, names=self.names)\n",
    "        \n",
    "    def crossover(self, p1, p2):\n",
    "        # children are copies of parents by default\n",
    "        c1, c2 = p1.copy(), p2.copy()\n",
    "        # check for recombination\n",
    "        if rand() < self.crossover_rate:\n",
    "            # select crossover point that is not on the end of the string\n",
    "            pt = randint(1, len(p1)-2)\n",
    "            # perform crossover\n",
    "            c1 = p1[:pt] + p2[pt:]\n",
    "            c2 = p2[:pt] + p1[pt:]\n",
    "        return [c1, c2]\n",
    "    \n",
    "    def mutation(self, bitstring):\n",
    "        # mutation operator\n",
    "        mutation_indx = np.random.rand(len(bitstring))<self.mutation_rate\n",
    "        bitstring[mutation_indx] = 1-bitstring[mutation_indx]\n",
    "        return bitstring\n",
    "    \n",
    "    def selection(pop, scores, k=3):\n",
    "        # selection is based on the score of roulette wheel method\n",
    "        probs = scores/np.sum(scores) ## probabilities associated with each individual based on recognition fitness score\n",
    "        return np.random.choice(pop, p = probs)\n",
    "    \n",
    "    def step(self, pop, n_pop, best, best_eval, gen):\n",
    "        '''\n",
    "        Performs a single step for optimization\n",
    "        '''\n",
    "        scores = self.recognition._recognition(pop=pop, n_pop=n_pop)\n",
    "        # check for new best solution\n",
    "        for i in range(n_pop):\n",
    "            if scores[i] > best_eval:\n",
    "                best, best_eval = pop[i], scores[i]\n",
    "                print(\">%d, new best f(%s) = %.3f\" % (gen,  pop[i], scores[i]))\n",
    "        # select parents\n",
    "        selected = [self.selection(pop, scores) for _ in range(n_pop)]\n",
    "        # create the next generation\n",
    "        children = []\n",
    "        for i in range(0, n_pop, 2):\n",
    "            # get selected parents in pairs\n",
    "            p1, p2 = selected[i], selected[i+1]\n",
    "            # crossover and mutation\n",
    "            for c in self.crossover(p1, p2):\n",
    "                # mutation\n",
    "                c = self.mutation(c)\n",
    "                # store for next generation\n",
    "                children.append(c)\n",
    "        # replace population\n",
    "        pop = children\n",
    "        return [pop, best, best_eval]\n",
    "    \n",
    "    def process(self, n_features, precentage_features, n_iter, n_pop):\n",
    "        trim_indx = int(precentage_features*n_features)\n",
    "        pop = np.uint8(np.arange(n_features)>=trim_indx) ## valid pattern for our solution\n",
    "        np.random.shuffle(pop) ## shuffling to create initial population\n",
    "        # keep track of best solution\n",
    "        best, best_eval = 0, 0\n",
    "        # enumerate generations\n",
    "        for gen in range(n_iter):\n",
    "            pop, best, best_eval = self.step(pop, n_pop, best, best_eval, gen)\n",
    "        return [best, best_eval]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "982e651b94398953ffcf43eade11b6f76e0faff8bb43f110ed109193ea4b0bcf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('oe_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
