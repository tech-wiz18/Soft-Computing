{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision.models import *\n",
    "\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class PairedDataset(Dataset):#Get two images and whether they are related.\n",
    "    \n",
    "    def __init__(self, features, names):\n",
    "        self.features = features\n",
    "        self.full_names = names\n",
    "        self.value_cnts = pd.value_counts(self.full_names)\n",
    "        self.names = np.unique(names)\n",
    "        \n",
    "    def get_pair(self, positive):\n",
    "        pair = []\n",
    "        if positive:\n",
    "            while True:\n",
    "                value = random.choice(self.names)\n",
    "                if self.value_cnts[value]>=2:\n",
    "                    id = [value, value]\n",
    "                    break\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "            while True:\n",
    "                id = [random.choice(self.names), random.choice(self.names)]\n",
    "                if id[0] != id[1]:\n",
    "                    break\n",
    "        \n",
    "        for i in range(2):\n",
    "            if i==1:\n",
    "              while True:\n",
    "                indx = np.random.choice(np.where(self.full_names==id[i])[0])  \n",
    "                if indx!=pair[0]:\n",
    "                    pair.append(indx)\n",
    "                    break\n",
    "            else:\n",
    "                pair.append(np.random.choice(np.where(self.full_names==id[i])[0]))\n",
    "        # print(pair)\n",
    "        # print(self.features.shapes)\n",
    "        f1 =  torch.from_numpy(self.features[pair[0], :].reshape(1,-1))\n",
    "        f2 =  torch.from_numpy(self.features[pair[1], :].reshape(1,-1))\n",
    "            \n",
    "            \n",
    "        return f1, f2, torch.tensor(label).long()\n",
    "  \n",
    "    def __getitem__(self,index):\n",
    "        #we need to make sure approx 50% of images are in the same class\n",
    "        should_get_same_class = random.randint(0,1) \n",
    "        f1, f2, label = self.get_pair(should_get_same_class)\n",
    "        return f1, f2, label \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]#essential for choose the num of data in one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SB_Block(nn.Module):\n",
    "    '''\n",
    "    Siamese Convolutional Block\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(SB_Block, self).__init__()\n",
    "        self.min = self.Mini_Block()\n",
    "    \n",
    "    def Mini_Block(self):\n",
    "        '''\n",
    "        Mini block in simaese convolutions\n",
    "        '''\n",
    "        return nn.Sequential(OrderedDict([\n",
    "          ('linear1',  nn.Linear(240,128)),\n",
    "          ('relu1', nn.ReLU(inplace=True)),\n",
    "          ('linear2',  nn.Linear(128,128)),\n",
    "          ('relu2', nn.ReLU(inplace=True)),\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        '''\n",
    "        Forward pass of a single SB block\n",
    "        '''\n",
    "        # print(input1.shape)\n",
    "        f11 = self.min(input1)\n",
    "        # print(f\"f11 - {f11.shape}\")\n",
    "        f12 = self.min(input2)\n",
    "        # print(f\"f12 - {f11.shape}\")\n",
    "        diff = f11-f12\n",
    "        # print(f\"diff shape - {diff.shape}\")\n",
    "        return diff\n",
    "    \n",
    "class network(nn.Module):\n",
    "    '''\n",
    "    the complete network implementation for our network\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(network, self).__init__()\n",
    "        self.SB = SB_Block()\n",
    "        self.output = nn.Linear(128,2)\n",
    "        \n",
    "    def forward(self, f1, f2):\n",
    "        # print(f\"f1 - {f1.shape}, f2 - {f2.shape}\")\n",
    "        fc = self.SB(f1, f2)\n",
    "        # print(f\"fc - {fc.shape}\")\n",
    "        out = self.output(fc)\n",
    "        # print(\"OUT SHAPE\", out.shape)\n",
    "        out = out.squeeze(dim = 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore below few cells, as it run for only once, and then stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading selected features from evolutionary algorithm\n",
    "selected_features = []\n",
    "for line in open(\"../config/evol_chkpts/best.txt\"):\n",
    "    if line.strip():\n",
    "        selected_features.append(int(line))\n",
    "selected_features = np.array(selected_features, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading wavelet eigen vals, train_wavelet dataset and test_wavelet dataset\n",
    "\n",
    "eigen_vecs = pd.read_csv(\"../data/eigen_vecs_wavelet.csv\")\n",
    "train_data = pd.read_csv(\"../data/wavelet_std_features.csv\")\n",
    "test_data = pd.read_csv(\"../data/wavelet_std_features_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = train_data[\"names\"]\n",
    "test_names = test_data[\"names\"]\n",
    "test_data = test_data[test_data.columns[:-1]].values\n",
    "train_data = train_data[train_data.columns[:-1]].values\n",
    "eigen_vecs = eigen_vecs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_eigens = eigen_vecs[:, selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = (selected_eigens.T@train_data.T).T\n",
    "test_features = (selected_eigens.T@test_data.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del train_data, test_data, selected_eigens, eigen_vecs\n",
    "gc.collect()\n",
    "\n",
    "train_features = train_features.astype(\"float32\")\n",
    "test_features = test_features.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names, test_names = np.array(train_names), np.array(test_names)\n",
    "np.save(\"../data/train_names.npy\", train_names)\n",
    "np.save(\"../data/test_names.npy\", test_names)\n",
    "np.save(\"../data/train_features.npy\", train_features)\n",
    "np.save(\"../data/test_features.npy\", test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN FROM HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = np.load(\"../data/train_names.npy\", allow_pickle = True)\n",
    "test_names = np.load(\"../data/test_names.npy\", allow_pickle = True)\n",
    "train_features = np.load(\"../data/train_features.npy\")\n",
    "test_features = np.load(\"../data/test_features.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = PairedDataset(train_features , train_names)\n",
    "train_loader = DataLoader(trainset,\n",
    "                        shuffle=True,#whether randomly shuffle data in each epoch, but cannot let data in one batch in order.\n",
    "                        num_workers=8, \n",
    "                        batch_size = 32)\n",
    "\n",
    "valset = PairedDataset(test_features , test_names)\n",
    "validation_loader = DataLoader(valset,\n",
    "                        shuffle=True,#whether randomly shuffle data in each epoch, but cannot let data in one batch in order.\n",
    "                        num_workers = 8, \n",
    "                        batch_size =32)\n",
    "\n",
    "model = network()\n",
    "device = torch.device('cuda:0')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # computes softmax and then the cross entropy\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay = 0.0005)\n",
    "\n",
    "lambda1 = lambda epoch: 0.01 * ((0.0001 * epoch + 1) ** -0.75)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "\n",
    "epochs = 30\n",
    "iteration = 0\n",
    "\n",
    "if os.path.exists('../config/model_chkpts/logs'):\n",
    "    checkpoint = torch.load('../model_chkpts/logs')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    exp_lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    iteration = checkpoint['iteration']\n",
    "    print('Restore model at iteration - ', iteration)\n",
    "\n",
    "for i in range(epochs):\n",
    "    val_acc = []\n",
    "    val_loss = []\n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    \n",
    "    model.train() # setting for training\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        img0, img1 , labels = data #img=tensor[batch_size,channels,width,length], label=tensor[batch_size,label]\n",
    "        img0, img1 , labels = img0.to(device), img1.to(device) , labels.to(device)#move to GPU\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(img0, img1)\n",
    "        # print(logits.shape, labels.shape)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        total = len(labels)\n",
    "        correct = torch.sum(preds==labels)\n",
    "        train_acc.append(correct.item()/total)\n",
    "        iteration +=1\n",
    "        # print('Iteration: {}, learning rate: {:.7f}, Loss: {:.4f}, Accuracy:{:.3f}'.format(iteration, \n",
    "        #                                                                                optimizer.param_groups[0][\"lr\"], \n",
    "        #                                                                                loss.item(), correct.item()/total))\n",
    "        exp_lr_scheduler.step()\n",
    "        # if iteration%100==0:\n",
    "        #     print(iteration)\n",
    "        if iteration%5 == 0:\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': exp_lr_scheduler.state_dict(),\n",
    "                }, '../config/model_chkpts/logs')\n",
    "        \n",
    "    model.eval() # setting for training\n",
    "    \n",
    "    for batch_idx, data in enumerate(validation_loader):\n",
    "        # if iteration%10==0:\n",
    "        #     print(iteration)\n",
    "        img0, img1 , labels = data #img=tensor[batch_size,channels,width,length], label=tensor[batch_size,label]\n",
    "        img0, img1 , labels = img0.to(device), img1.to(device) , labels.to(device)#move to GPU\n",
    "        \n",
    "        logits = model(img0, img1)\n",
    "        loss = F.cross_entropy(logits, labels, reduction = 'sum')/len(img0)\n",
    "\n",
    "        val_loss.append(loss.item())\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        total = len(labels)\n",
    "        correct = torch.sum(preds==labels)\n",
    "        val_acc.append(correct.item()/total)  \n",
    "    \n",
    "    print('Epoch: {}, Loss: {:.4f}, Accuracy:{:.3f}, Val Loss: {:.4f}, Val Accuracy: {:.3f}'.format(\n",
    "        i+1, np.mean(train_loss), np.mean(train_acc),np.mean(val_loss), np.mean(val_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIfferent Face\n"
     ]
    }
   ],
   "source": [
    "image_path1 = \"/media/amshra267/New Volume/CV/Soft-Computing/lfwcrop_color/sample_faces/Aaron_Eckhart_0001.ppm\"\n",
    "image_path2 = \"/media/amshra267/New Volume/CV/Soft-Computing/lfwcrop_color/sample_faces/Abdul_Majeed_Shobokshi_0001.ppm\"\n",
    "\n",
    "img1, (_, _, _) = pywt.dwt2(cv2.cvtColor(cv2.imread(image_path1), cv2.COLOR_BGR2GRAY), \"db4\")\n",
    "img2, (_, _, _) = pywt.dwt2(cv2.cvtColor(cv2.imread(image_path2), cv2.COLOR_BGR2GRAY), \"db4\")\n",
    "\n",
    "\n",
    "## loading selected features from evolutionary algorithm\n",
    "selected_features = []\n",
    "for line in open(\"../config/evol_chkpts/best.txt\"):\n",
    "    if line.strip():\n",
    "        selected_features.append(int(line))\n",
    "selected_features = np.array(selected_features, dtype=bool)\n",
    "\n",
    "## loading wavelet pca mean from evolutionary algorithm\n",
    "wave_mean = []\n",
    "for line in open(\"../config/wavelet_mean.txt\"):\n",
    "    if line.strip():\n",
    "        wave_mean.append(float(line))\n",
    "wave_mean = np.array(wave_mean).reshape(1,-1)\n",
    "\n",
    "thresh = 0.4\n",
    "eigen_vecs = pd.read_csv(\"../data/eigen_vecs_wavelet.csv\").values\n",
    "selected_eigens = eigen_vecs[:, selected_features]\n",
    "\n",
    "\n",
    "## image preprocessing\n",
    "img1 = img1.reshape(1,-1)\n",
    "img2 = img2.reshape(1,-1)\n",
    "\n",
    "img1 = (img1-wave_mean)/255\n",
    "img2 = (img2-wave_mean)/255\n",
    "\n",
    "img1 = ((selected_eigens.T@img1.T)).T\n",
    "img2 = ((selected_eigens.T@img2.T)).T\n",
    "img1 = torch.from_numpy(img1)\n",
    "img2 = torch.from_numpy(img2)\n",
    "\n",
    "## loading saved model\n",
    "\n",
    "model = network()\n",
    "device = torch.device('cuda:0')\n",
    "model = model.to(device)\n",
    "\n",
    "if os.path.exists('../../config/model_chkpts/logs'):\n",
    "    checkpoint = torch.load('../model_chkpts/logs')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    exp_lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    iteration = checkpoint['iteration']\n",
    "    print('Restore model at iteration - ', iteration)\n",
    "    \n",
    "\n",
    "## prediction\n",
    "img1, img2 = img1.to(device).float(), img2.to(device).float()\n",
    "output = F.softmax(model(img1, img2))[0][0]\n",
    "if output>thresh:\n",
    "    print(\"DIfferent Face\")\n",
    "else:\n",
    "    print(\"Same Face\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "982e651b94398953ffcf43eade11b6f76e0faff8bb43f110ed109193ea4b0bcf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('oe_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
